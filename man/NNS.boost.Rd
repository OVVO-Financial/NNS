% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Boost.R
\name{NNS.boost}
\alias{NNS.boost}
\title{NNS Boost}
\usage{
NNS.boost(IVs.train, DV.train, IVs.test, representative.sample = TRUE,
  depth = NULL, n.best = 3, learner.trials = NULL, epochs = NULL,
  CV.size = 0.25, threshold = NULL,
  obj.fn = expression(mean(round(predicted) == as.numeric(actual))),
  objective = "max", extreme = FALSE, feature.importance = TRUE,
  status = TRUE, ncores = NULL, subcores = NULL)
}
\arguments{
\item{IVs.train}{a matrix or data frame of variables of numeric or factor data types.}

\item{DV.train}{a numeric or factor vector with compatible dimsensions to \code{(IVs.train)}.}

\item{IVs.test}{a matrix or data frame of variables of numeric or factor data types with compatible dimsensions to \code{(IVs.train)}.}

\item{representative.sample}{logical; \code{TRUE} (default) Reduces observations of \code{IVs.train} to a set of representative observations per regressor.}

\item{depth}{integer; \code{NULL} (default) Specifies the \code{order} parameter in the \code{NNS.reg} routine, assigning a number of splits in the regressors.  \code{(depth = "max")} will be signifcantly faster, but increase the variance of results.}

\item{n.best}{integer; \code{3} (default) Sets the number of nearest regression points to use in weighting for multivariate regression at \code{sqrt(# of regressors)}. Analogous to \code{k} in a \code{k Nearest Neighbors} algorithm.}

\item{learner.trials}{integer; \code{NULL} (default) Sets the number of trials to obtain an accuracy \code{threshold} level.  Number of observations in the training set is the default setting.}

\item{epochs}{integer; \code{2*length(DV.train)} (default) Total number of feature combinations to run.}

\item{CV.size}{numeric [0, 1]; \code{(CV.size = .25)} (default) Sets the cross-validation size.  Defaults to 0.25 for a 25 percent random sampling of the training set.}

\item{threshold}{numeric [0, 1]; \code{NULL} (default) Sets the \code{obj.fn} accuracy threshold to keep feature combinations.}

\item{obj.fn}{expression;
\code{expression(mean(round(predicted)==as.numeric(actual)))} (default) Mean accuracy is the default objective function.  Any \code{expression()} using the specific terms \code{predicted} and \code{actual} can be used.}

\item{objective}{options: ("min", "max") \code{"max"} (default) Select whether to minimize or maximize the objective function \code{obj.fn}.}

\item{extreme}{logical; \code{FALSE} (default) Uses the maximum (minimum) \code{threshold} obtained from the \code{learner.trials}, rather than the upper (lower) quintile level for maximization (minimization) \code{objective}.}

\item{feature.importance}{logical; \code{TRUE} (default) Plots the frequency of features used in the final estimate.}

\item{status}{logical; \code{TRUE} (default) Prints status update message in console.}

\item{ncores}{integer; value specifying the number of cores to be used in the parallelized procedure. If NULL (default), the number of cores to be used is equal to half the number of cores of the machine.}

\item{subcores}{integer; value specifying the number of cores to be used in the parallelized procedure in the subroutine \link{NNS.reg}.  If NULL (default), the number of cores to be used is equal to half the number of cores of the machine - 1.}
}
\value{
Returns a vector of fitted values for the dependent variable test set.
}
\description{
Ensemble method for classification using the predictions of the NNS multivariate regression \link{NNS.reg} collected from uncorrelated feature combinations.
}
\examples{
 ## Using 'iris' dataset where test set [IVs.test] is 'iris' rows 141:150.
 \dontrun{
 a <- NNS.boost(iris[1:140, 1:4], iris[1:140, 5],
 IVs.test = iris[141:150, 1:4],
 epochs = 100, learner.trials = 100)

 ## Test accuracy
 mean(round(a)==as.numeric(iris[141:150,5]))
 }

}
\references{
Viole, F. (2016) "Classification Using NNS Clustering Analysis"
\url{https://ssrn.com/abstract=2864711}
}
\author{
Fred Viole, OVVO Financial Systems
}
