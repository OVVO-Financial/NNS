<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Fred Viole" />


<title>Getting Started with NNS: Classification</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Getting Started with NNS:
Classification</h1>
<h4 class="author">Fred Viole</h4>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(NNS)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(knitr)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(rgl)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(meboot)</span></code></pre></div>
<div id="classification" class="section level1">
<h1>Classification</h1>
<p><strong><code>NNS.reg</code></strong> is a very robust regression
technique capable of nonlinear regressions of continuous variables and
classification tasks in machine learning problems.</p>
<p>We have extended the <strong><code>NNS.reg</code></strong>
applications per the use of an ensemble method of classification in
<strong><code>NNS.boost</code></strong>. In short,
<strong><code>NNS.reg</code></strong> is the base learner instead of
trees.</p>
<p><strong><em>One major advantage <code>NNS.boost</code> has over tree
based methods is the ability to seamlessly extrapolate beyond the
current range of observations.</em></strong></p>
<div id="splits-vs.-partitions" class="section level2">
<h2>Splits vs.Â Partitions</h2>
<p>Popular boosting algorithms take a series of weak learning decision
tree models, and aggregate their outputs. <code>NNS</code> is also a
decision tree of sorts, by partitioning each regressor with respect to
the dependent variable. We can directly control the number of âsplitsâ
with the <strong><code>NNS.reg(..., order = , ...)</code></strong>
parameter.</p>
<div id="nns-partitions" class="section level3">
<h3>NNS Partitions</h3>
<p>We can see how <code>NNS</code> partitions each regressor by calling
the <code>$rhs.partitions</code> output. You will notice that each
partition is not an equal interval, nor of equal length, which
differentiates <code>NNS</code> from other bandwidth or tree-based
techniques.</p>
<p>Higher dependence between a regressor and the dependent variable will
allow for a larger number of partitions. This is determined internally
with the <strong><code>NNS.dep</code></strong> measure.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">NNS.reg</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], iris[,<span class="dv">5</span>], <span class="at">residual.plot =</span> <span class="cn">FALSE</span>, <span class="at">ncores =</span> <span class="dv">1</span>)<span class="sc">$</span>rhs.partitions</span></code></pre></div>
<pre><code>##           V1       V2       V3  V4
##  1: 4.300000 2.000000 1.000000 0.1
##  2: 4.400643 2.200000 1.045833 0.2
##  3: 4.500000 2.300000 1.050000 0.3
##  4: 4.600000 2.400000 1.200000 0.4
##  5: 4.700000 2.500000 1.300000 0.5
##  6: 4.800000 2.600000 1.400000 0.6
##  7: 4.900000 2.700000 1.500000 1.0
##  8: 5.000000 2.800000 1.600000 1.1
##  9: 5.100000 2.900000 1.700000 1.2
## 10: 5.200000 3.000000 1.900000 1.3
## 11: 5.300000 3.100000 3.000000 1.4
## 12: 5.400000 3.200000 3.300000 1.5
## 13: 5.500000 3.300000 3.500000 1.6
## 14: 5.600000 3.400000 3.600000 1.7
## 15: 5.700000 3.500000 3.626426 1.8
## 16: 5.800000 3.600000 3.700000 1.9
## 17: 5.900000 3.700000 3.800000 2.0
## 18: 6.000000 3.800000 3.900000 2.1
## 19: 6.100000 3.900000 4.000000 2.2
## 20: 6.200000 4.000000 4.100000 2.3
## 21: 6.300000 4.145735 4.200000 2.4
## 22: 6.400000 4.145885 4.213849 2.5
## 23: 6.500000 4.150000 4.300000  NA
## 24: 6.600000 4.400000 4.400000  NA
## 25: 6.700000       NA 4.500000  NA
## 26: 6.800000       NA 4.600000  NA
## 27: 6.900000       NA 4.700000  NA
## 28: 7.000000       NA 4.800000  NA
## 29: 7.050477       NA 4.900000  NA
## 30: 7.200000       NA 5.000000  NA
## 31: 7.200174       NA 5.100000  NA
## 32: 7.349020       NA 5.200000  NA
## 33: 7.600000       NA 5.300000  NA
## 34: 7.700000       NA 5.400000  NA
## 35: 7.900000       NA 5.500000  NA
## 36:       NA       NA 5.600000  NA
## 37:       NA       NA 5.700000  NA
## 38:       NA       NA 5.800907  NA
## 39:       NA       NA 5.816250  NA
## 40:       NA       NA 5.936170  NA
## 41:       NA       NA 6.091466  NA
## 42:       NA       NA 6.386299  NA
## 43:       NA       NA 6.398696  NA
## 44:       NA       NA 6.700000  NA
## 45:       NA       NA 6.710561  NA
## 46:       NA       NA 6.900000  NA
##           V1       V2       V3  V4</code></pre>
</div>
</div>
</div>
<div id="nns.boost" class="section level1">
<h1><code>NNS.boost()</code></h1>
<p>Through resampling of the training set and letting each iterated set
of data speak for themselves (while paying extra attention to the
residuals throughout), we can test various regressor combinations in
these dynamic decision treesâ¦only keeping those combinations that add
predictive value. From there we simply aggregate the predictions.</p>
<p><strong><code>NNS.boost</code></strong> will automatically search for
an accuracy <code>threshold</code> from the training set, reporting
iterations remaining and level obtained in the console. A plot of the
frequency of the learning accuracy on the training set is also
provided.</p>
<p>Once a <code>threshold</code> is obtained,
<strong><code>NNS.boost</code></strong> will test various feature
combinations against different splits of the training set and report
back the frequency of each regressor used in the final estimate.</p>
<p>Letâs have a look and see how it works. We use 140 random
<code>iris</code> observations as our training set with the 10 holdout
observations as our test set. For brevity, we set
<code>epochs = 10, learner.trials = 10, folds = 1</code>.</p>
<p><strong>NOTE: Base category of response variable should be 1, not 0
for classification problems when using
<code>NNS.boost(..., type = &quot;CLASS&quot;)</code></strong>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>test.set <span class="ot">=</span> <span class="dv">141</span><span class="sc">:</span><span class="dv">150</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">NNS.boost</span>(<span class="at">IVs.train =</span> iris[<span class="sc">-</span>test.set, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">DV.train =</span> iris[<span class="sc">-</span>test.set, <span class="dv">5</span>],</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">IVs.test =</span> iris[test.set, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>],</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">epochs =</span> <span class="dv">10</span>, <span class="at">learner.trials =</span> <span class="dv">10</span>, </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">status =</span> <span class="cn">FALSE</span>, <span class="at">balance =</span> <span class="cn">TRUE</span>,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">type =</span> <span class="st">&quot;CLASS&quot;</span>, <span class="at">folds =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>a<span class="sc">$</span>results</span></code></pre></div>
<pre><code>##  [1] 3 3 3 3 3 3 3 3 3 3</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>a<span class="sc">$</span>feature.weights</span></code></pre></div>
<pre><code>##  Petal.Width Petal.Length Sepal.Length 
##    0.5000000    0.3333333    0.1666667</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>( a<span class="sc">$</span>results <span class="sc">==</span> <span class="fu">as.numeric</span>(iris[test.set, <span class="dv">5</span>]) )</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>A perfect classification, using the features: Petal.Width,
Petal.Length, Sepal.Length, weighted per the output above.</p>
</div>
<div id="cross-validation-classification-using-nns.stack" class="section level1">
<h1>Cross-Validation Classification Using <code>NNS.stack()</code></h1>
<p>The <strong><code>NNS.stack()</code></strong> routine cross-validates
for a given objective function the <code>n.best</code> parameter in the
multivariate <strong><code>NNS.reg</code></strong> function as well as
the <code>threshold</code> parameter in the dimension reduction
<strong><code>NNS.reg</code></strong> version.
<strong><code>NNS.stack</code></strong> can be used for classification
via
<strong><code>NNS.stack(..., type = &quot;CLASS&quot;, ...)</code></strong>.</p>
<p>For brevity, we set <code>folds = 1</code>.</p>
<p><strong>NOTE: Base category of response variable should be 1, not 0
for classification problems when using
<code>NNS.stack(..., type = &quot;CLASS&quot;)</code></strong>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">NNS.stack</span>(<span class="at">IVs.train =</span> iris[<span class="sc">-</span>test.set, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">DV.train =</span> iris[<span class="sc">-</span>test.set, <span class="dv">5</span>],</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">IVs.test =</span> iris[test.set, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>],</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">type =</span> <span class="st">&quot;CLASS&quot;</span>, <span class="at">balance =</span> <span class="cn">TRUE</span>,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">ncores =</span> <span class="dv">1</span>, <span class="at">folds =</span> <span class="dv">1</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>b</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>OBJfn.reg</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>NNS.reg.n.best</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>probability.threshold</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.451</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>OBJfn.dim.red</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.9714286</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>NNS.dim.red.threshold</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.8575</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>reg</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a> [<span class="dv">1</span>] <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>dim.red</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a> [<span class="dv">1</span>] <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>stack</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a> [<span class="dv">1</span>] <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span></span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>( b<span class="sc">$</span>stack <span class="sc">==</span> <span class="fu">as.numeric</span>(iris[test.set, <span class="dv">5</span>]) )</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">1</span></span></code></pre></div>
<div id="brief-notes-on-other-parameters" class="section level2">
<h2>Brief Notes on Other Parameters</h2>
<ul>
<li><p><code>depth = &quot;max&quot;</code> will force all observations to be
their own partition, forcing a perfect fit of the multivariate
regression. In essence, this is the basis for a <code>kNN</code> nearest
neighbor type of classification.</p></li>
<li><p><code>n.best = 1</code> will use the single nearest neighbor.
When coupled with <code>depth = &quot;max&quot;</code>, <code>NNS</code> will
emulate a <code>kNN = 1</code> but as the dimensions increase the
results diverge demonstrating <code>NNS</code> is less sensitive to the
curse of dimensionality than <code>kNN</code>.</p></li>
<li><p><code>extreme</code> will use the maximum or minimum
<code>threshold</code> obtained, and may result in errors if that
threshold cannot be eclipsed by subsequent iterations.</p></li>
</ul>
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p>If the user is so motivated, detailed arguments further examples are
provided within the following:</p>
<ul>
<li><p><a href="https://www.amazon.com/dp/1490523995/ref=cm_sw_su_dp">Nonlinear
Nonparametric Statistics: Using Partial Moments</a></p></li>
<li><p><a href="https://www.ssrn.com/abstract=2148522">Deriving
Nonlinear Correlation Coefficients from Partial Moments</a></p></li>
<li><p><a href="https://link.springer.com/article/10.1007/s10614-017-9713-5">Nonparametric
Regression Using Clusters</a></p></li>
<li><p><a href="https://www.ssrn.com/abstract=2861339">Clustering and
Curve Fitting by Line Segments</a></p></li>
<li><p><a href="https://www.ssrn.com/abstract=2864711">Classification
Using NNS Clustering Analysis</a></p></li>
</ul>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
