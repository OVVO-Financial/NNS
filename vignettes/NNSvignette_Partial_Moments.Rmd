---
title: "Getting Started with NNS: Partial Moments"
author: "Fred Viole"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started with NNS: Partial Moments}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(NNS)
```

# Partial Moments

Why is it necessary to parse the variance with partial moments?  The additional information generated from partial moments permits a level of analysis simply not possible with traditional summary statistics.

Below are some basic equivalences demonstrating partial moments role as the elements of variance.

##Mean
```{r mean}
set.seed(123); x=rnorm(100); y=rnorm(100)

mean(x)
UPM(1,0,x)-LPM(1,0,x)
```

##Variance
```{r variance}
var(x)

# Sample Variance:
UPM(2,mean(x),x)+LPM(2,mean(x),x)

# Population Variance:
(UPM(2,mean(x),x)+LPM(2,mean(x),x))*(length(x)/(length(x)-1))

# Variance is also the co-variance of itself:
(Co.LPM(1,1,x,x,mean(x),mean(x))+Co.UPM(1,1,x,x,mean(x),mean(x))-D.LPM(1,1,x,x,mean(x),mean(x))-D.UPM(1,1,x,x,mean(x),mean(x)))*(length(x)/(length(x)-1))
```


##Standard Deviation
```{r stdev}
sd(x)
((UPM(2,mean(x),x)+LPM(2,mean(x),x))*(length(x)/(length(x)-1)))^.5
```

##Covariance
```{r covariance}
cov(x,y)
(Co.LPM(1,1,x,y,mean(x),mean(y))+Co.UPM(1,1,x,y,mean(x),mean(y))-D.LPM(1,1,x,y,mean(x),mean(y))-D.UPM(1,1,x,y,mean(x),mean(y)))*(length(x)/(length(x)-1))
```

##Covariance Elements and Covariance Matrix
```{r cov_dec}
PM.matrix(LPM.degree = 1,UPM.degree = 1,target = 'mean', variable = cbind(x,y), pop.adj = TRUE)
```

##Pearson Correlation
```{r pearson}
cor(x,y)
cov.xy=(Co.LPM(1,1,x,y,mean(x),mean(y))+Co.UPM(1,1,x,y,mean(x),mean(y))-D.LPM(1,1,x,y,mean(x),mean(y))-D.UPM(1,1,x,y,mean(x),mean(y)))*(length(x)/(length(x)-1))
sd.x=((UPM(2,mean(x),x)+LPM(2,mean(x),x))*(length(x)/(length(x)-1)))^.5
sd.y=((UPM(2,mean(y),y)+LPM(2,mean(y),y))*(length(y)/(length(y)-1)))^.5
cov.xy/(sd.x*sd.y)
```

##CDFs (Discrete and Continuous)
```{r cdfs}
P=ecdf(x)
P(0);P(1)
LPM(0,0,x);LPM(0,1,x)

# Vectorized targets:
LPM(0,c(0,1),x)

plot(ecdf(x))
points(sort(x),LPM(0,sort(x),x),col='red')
legend('left',legend=c('ecdf','LPM.CDF'),fill=c('black','red'),border=NA,bty='n')

# Joint CDF:
Co.LPM(0,0,x,y,0,0)

# Vectorized targets:
Co.LPM(0,0,x,y,c(0,1),c(0,1))

# Continuous CDF:
plot(sort(x),LPM.ratio(1,sort(x),x),type = 'l',col='blue',lwd=3,xlab="x")
```


##PDFs
```{r pdfs}
NNS.PDF(degree=1,x)
```

##Numerical Integration
Partial moments are asymptotic area approximations of $f(x)$ akin to the familiar Trapezoidal and Simpson's rules.  More observations, more accuracy...

$$[UPM(1,0,f(x))-LPM(1,0,f(x))]\asymp\frac{[F(b)-F(a)]}{[b-a]}$$

```{r numerical integration}
x=seq(0,1,.001);y=x^2
UPM(1,0,y)-LPM(1,0,y)
```

$$0.3333=\frac{\int_{0}^{1} x^2 dx}{1-0}$$
For the total area, not just the definite integral, simply sum the partial moments:
$$[UPM(1,0,f(x))+LPM(1,0,f(x))]\asymp\left\lvert{\int_{a}^{b} f(x)dx}\right\rvert$$

##Bayes' Theorem
For example, when ascertaining the probability of an increase in $A$ given an increase in $B$, the `Co.UPM(degree.x,degree.y,x,y,target.x,target.y)` target parameters are set to `target.x=0` and `target.y=0` and the `UPM(degree,target,variable)` target parameter is also set to `target=0`.

$$P(A|B)=\frac{Co.UPM(0,0,A,B,0,0)}{UPM(0,0,B)}$$

#References
If the user is so motivated, detailed arguments and proofs are provided within the following:

* [Nonlinear Nonparametric Statistics: Using Partial Moments](http://a.co/5bpHvUg)

* [Cumulative Distribution Functions and UPM/LPM Analysis](https://ssrn.com/abstract=2148482)

* [f(Newton)](https://ssrn.com/abstract=2186471)

* [Bayes' Theorem From Partial Moments](https://github.com/OVVO-Financial/NNS/blob/NNS-Beta-Version/examples/Bayes'%20Theorem%20From%20Partial%20Moments.pdf)
